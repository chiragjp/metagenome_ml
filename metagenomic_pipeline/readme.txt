###Metagenomics Pipeline

The following scripts can guide you through the metagenomics aspects of our project. At the end of it all, you should have:

1) A species-level abundance matrix generated by MetaPhlAn2
2) A pathway-level abundance matrix generated by alignment to the BioCyc Tier3 database
3) Co-abundance Groups of clustered, normalized genes
4) Normalized gene abundance for each gene in your catalog

All the files have in them the arguments they take, and any executables mentioned in the description must be in the path (or specified in the code) for the scripts to run successfully.

This pipeline is a combination of Python2.7 scripts and short bash scripts. The only Python dependencies should be Pandas, Numpy, and click.

Certain bash scripts (i.e. running MetaPhlan2 on each sample) will need to be run for each sample. 

####Analytic steps and associated scripts

#####Assembly and ORF calling
assembly_and_annotation.sh < Use MEGAHIT (http://www.metagenomics.wiki/tools/assembly/megahit) _de novo_ assembler to assemble reads into contigs, from which PROKKA (https://github.com/tseemann/prokka) is used to predict Open-Reading-Frames (hereafter referred to as genes).

#####Gene catalog construction and filtering
run_cdhit.sh < Cat all of your PROKKA predicted genes (the .ffn files together and then use CD-HIT-EST (https://github.com/weizhongli/cdhit/releases) to create a non-redundant gene catalog from this one, large file.
remove_short_sequences_from_gene_catalog_consensus_genes.py < In accordance with the literature, we removed short genes (less than 100 base pairs) from the catalog. This script takes 4 arguments, your cdhit output consensus sequence fasta file, two output files (the removed genes and the ones you keep), and a diamond (https://github.com/bbuchfink/diamond) index that you want to align the short genes against, in case they have close matches, making them possibly worth keeping. We used a diamond index of NCBI's NR database (ftp://ftp.ncbi.nlm.nih.gov/blast/db/FASTA/nr.gz), but you can supply your own.
prep_clusterfile_for_filtering.sh < Create sorted list of short gene ids to be removed from the clusterfile
remove_short_sequences_from_clusterfile.py < Takes the output of the previous script and removes the short genes from the cdhit clusterfile output.

#####Quantification gene abundance per sample 
align.sh < For each sample, compute number of reads aligning to each gene in gene catalog using bowtie2 (http://bowtie-bio.sourceforge.net/bowtie2/index.shtml)
create_raw_abundance_matrix_from_alignment_files.sh < Build raw abundance (count) matrix from alignment files
normalize_raw_abundance_matrix.py < Normalize read alignment counts by depth of sequencing per sample and length of each gene

#####Pathway abundance quantification
download_biocyc_db.sh < Download and unpack BioCyc Tier3 Diamond alignment index.
annotate_gene_catalog_against_biocyc.py < Align gene catalog against diamond database, take aligned genes and collapse into pathways using abundance matrix

#####CAG generation
prep_normalized_matrix_for_cags.sh < Convert normalized abundance matrix to format needed for input into canopy clustering algorithm
generate_cags.sh < Build CAGs with the canopy clustering algorithm (https://bitbucket.org/HeyHo/mgs-canopy-algorithm/wiki/Obtaining%20the%20executable)

#####run MetaPhlAn2
run_metaphlan.sh < For each sample, you can use this script run MetaPhlAn2 (https://bitbucket.org/biobakery/metaphlan2/src/default/) to compute species abundances
get_all_profiles.py < Put all the output from the prior step in a single directory. Pass the path to that directory, and it will generate your taxonomic abundance matrices.




